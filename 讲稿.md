## SGD with Momentum 

在基本随机梯度下降（SGD） 的基础上引入了动量（Momentum）

在标准 SGD 中，梯度更新的方向完全依赖于当前梯度，导致收敛速度较慢。Momentum 通过累积之前的梯度信息，使参数更新时更稳定，减少震荡，从而更快地朝最优解前进。

SGD 在鞍点附近可能会停滞，而 Momentum 允许优化器在梯度较小的区域继续前进，帮助逃离鞍点。

其更新公式如下：

1. 计算速度更新（Momentum term）：

   $$v_t= \beta v_{t-1} + (1 - \beta) \nabla L(\theta_t)$$

   其中：

   - $v_t$ 是当前的梯度积累动量（velocity）
   - $\beta$ 是动量系数（通常取 0.9）
   - $\nabla L(\theta_t)$ 是损失函数关于参数 $\theta_t$ 的梯度
   - $v_{t-1}$ 是上一步的动量

2. 更新参数：

   $$θ_t=θ_{t−1}−αv_t$$

   其中：

   - $\alpha$ 是学习率（learning rate）



可以把 Momentum 类比成“滚动的小球”：

- 纯 SGD 类似于小球仅受重力作用，遇到障碍时可能会卡住或缓慢滚动；
- Momentum 相当于给小球加了惯性，即使遇到较小的坡度也能继续前进。

------





## AdaGrad 

Adaptive Gradient (AdaGrad) 是一种自适应学习率优化算法，旨在通过对不同参数的学习率进行单独调整，以提高优化效果，尤其适用于稀疏数据（如 NLP 任务）。

### 核心思想

- 自适应学习率：对于经常更新的参数，降低学习率；对于较少更新的参数，提高学习率。
- 累积历史梯度信息：通过计算每个参数的梯度平方和，使得参数的学习率随时间动态调整。

### 更新公式

给定损失函数 $L(\theta)$ 对参数 $\theta$ 的梯度 $g_t$：

1. 累积梯度平方：

   $$G_t=G_{t−1}+g_t^2 $$

   - 这里 $G_t$ 是所有时间步的梯度平方和。

2. 计算更新步长：

   θt=θt−1−αGt+ϵgt\theta_t = \theta_{t-1} - \frac{\alpha}{\sqrt{G_t} + \epsilon} g_t

   - $\alpha$ 是学习率。
   - $\epsilon$ 是防止除零的小值（如 $10^{-8}$）。
   - 不同参数的学习率不同，梯度较大的参数其学习率会逐步减小。

------

## AdaGrad 在 SGD with Momentum 上的改进

AdaGrad 主要改进了 SGD with Momentum 在不同参数上的学习率调节问题：

1. SGD with Momentum 依赖固定的学习率 $\alpha$，即使动量项使得梯度方向更稳定，仍然可能因为固定学习率而难以调整不同参数的更新幅度。
2. AdaGrad 解决了这一问题，通过历史梯度平方和来动态调整学习率，使得：
   - 常见更新的参数学习率变小（防止震荡）。
   - 罕见更新的参数学习率变大（避免停滞）。

但 AdaGrad 存在的问题：

- 随着训练进行，梯度平方和 $G_t$ 会不断增大，导致学习率持续减小，可能会过早收敛，甚至停滞。







- **RMSProp 解决了 AdaGrad 学习率持续减小的问题，引入指数衰减的梯度平方均值。**

  

### **RMSProp **

**由 Geoffrey Hinton 在 2012 年提出。它主要用于解决 AdaGrad（Adaptive Gradient）优化器学习率衰减过快的问题

------

### **RMSProp 的原理**

RMSProp 通过 指数加权移动平均（EMA, Exponentially Moving Average） 计算梯度平方的累积值，从而调整学习率，使参数更新更加稳定。

#### 1️⃣ 计算梯度的平方的指数加权平均

对于每个参数 $w_t$，计算梯度平方的指数加权平均：

$E[g^2]_t = \beta E[g^2]_{t-1} + (1 - \beta) g_t^2$

- $g_t$ 是当前步的梯度。
- $E[g^2]_t$ 是梯度平方的滑动平均值（历史梯度平方的加权平均）。
- $\beta$ 是平滑系数（一般取 0.9）。
- 这样做的目的是让较远的过去梯度影响逐渐减弱，而近期梯度影响更大。
- **实际上和上一页相比**，只是在梯度平方前面加了平滑系数，“加权”

#### 2️⃣ 更新参数

$w_{t+1} = w_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t$

- $\eta$ 是初始学习率。
- $\epsilon$ 是一个小值（如 1e-8），用于防止分母变成零。
- 由于 RMSProp 采用的是梯度平方的滑动平均值来缩放学习率，梯度较大的参数更新幅度变小，梯度较小的参数更新幅度较大，从而避免梯度爆炸或梯度消失问题。

------







### **Adam（Adaptive Moment Estimation）优化器**

**Adam 由 Diederik Kingma 和 Jimmy Ba 在 2014 年提出。它结合了 Momentum（动量） 和 RMSProp 的思想，在大多数深度学习任务中表现良好，因此通常作为默认优化器。**

------

## **Adam 的原理**

**Adam 通过同时计算梯度的一阶矩（均值）和二阶矩（方差），自适应地调整不同参数的学习率，既具有Momentum 的加速收敛特性，又具备RMSProp 的自适应学习率能力。**

------

### **1️⃣ 计算梯度的一阶矩（动量估计）**

**Adam 采用指数加权移动平均的方法计算梯度的一阶矩（即动量,梯度的指数加权平均）：**

**$m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$**

- **$m_t$ 是当前时间步的梯度一阶矩（类似于 Momentum）。**
- **$g_t$ 是当前梯度。**
- **$\beta_1$ 是动量超参数（默认 0.9），控制一阶矩的平滑程度。**

**作用：类似于 Momentum，可以平滑梯度方向，减少震荡。**

------

### **2️⃣ 计算梯度的二阶矩（RMSProp 估计）**

**同时，Adam 也计算梯度的二阶矩（即梯度平方的指数加权移动平均）：**

**$v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2$**

- **$v_t$ 是当前时间步的梯度二阶矩（类似于 RMSProp）。**
- **$\beta_2$ 是超参数（默认 0.999），控制二阶矩的平滑程度。**

**作用：类似于 RMSProp，可以自适应调整学习率，避免梯度爆炸或消失。**

------

Adam 的 **一阶矩（First Moment）** 和 **二阶矩（Second Moment）** 分别可以类比为 **均值** 和 **方差**，但它们有一些细微的区别。

### **1. 一阶矩（First Moment）—— 类比均值**

如果展开这个公式，可以看到 $m_t$ 其实是对过去多个梯度的加权求和：

$m_t = (1 - \beta_1) \sum_{i=0}^{t} \beta_1^{t-i} g_i$

**类比：**

- 这类似于**均值（mean）**，因为它表示梯度的期望值。
- 但不同之处在于，普通均值会对所有过去的梯度赋予相同的权重，而 Adam 采用 **指数加权平均**（Exponential Moving Average, EMA），使得较新的梯度影响更大，而较旧的梯度影响逐渐减小。

------

### **2. 二阶矩（Second Moment）—— 类比方差**

如果展开这个公式：

$v_t = (1 - \beta_2) \sum_{i=0}^{t} \beta_2^{t-i} g_i^2$

可以看出，$v_t$ 记录的是 **梯度的波动情况**（即梯度的方差），用于调整学习率，使得梯度较大的参数更新步长变小，梯度较小的参数步长变大。

**类比：**

- 这类似于**方差（variance）**，因为它衡量的是梯度的波动程度。
- 但不同之处在于，普通方差会对所有过去的梯度平方赋予相同的权重，而 Adam 采用 **指数加权平均**，使得较新的梯度平方影响更大，较旧的影响逐渐减小。

------

### **3. 为什么要进行“偏差校正”？**

在 Adam 算法的初期，$m_t$ 和 $v_t$ 的数值可能会偏小，导致学习率过小。因此，Adam 采用 **偏差校正（Bias Correction）** 来调整一阶矩和二阶矩：

$\hat{m}_t = \frac{m_t}{1 - \beta_1^t}$$\hat{v}_t = \frac{v_t}{1 - \beta_2^t}$

这实际上是对指数加权平均的一个修正，使得在初始阶段不至于过度缩小学习率。



所以，一阶矩 $m_t$ 近似于均值，二阶矩 $v_t$ 近似于方差，但它们是基于指数加权平均（EMA）的变体，并不是直接的均值和方差计算方式。

------

## **Adam 的应用场景**

1. 默认优化器：适用于 CNN、RNN、Transformer 等深度神经网络，几乎是所有任务的首选优化器。
2. 适用于非平稳目标函数：在 NLP 和强化学习等任务中效果较好。
3. 适用于稀疏梯度问题：例如推荐系统、NLP（word embeddings）。

------

## **Adam 的缺点**

尽管 Adam 在大多数情况下表现优秀，但它也有一些问题：

1. 可能会收敛到较差的局部最优
   - Adam 可能会在训练后期收敛到一个“次优”解，而不是最优解。
   - 解决方案：使用 AdamW（权重衰减） 或 改用 SGD 进行微调。
2. 对 Batch Size 较敏感
   - Adam 在小 batch size 下表现良好，但在大 batch 下可能不如 SGD+Momentum。
3. 收敛速度快但泛化能力可能较差
   - Adam 适合快速优化损失，但有时候泛化性能（测试集表现）不如 SGD。
   - 解决方案：训练后期切换为 SGD（如 Adam -> SGD with Momentum）。

------









**在卷积神经网络（CNN, Convolutional Neural Network）中，隐藏层通常指的是输入层和输出层之间的所有层。具体来说：**

- **卷积层（Convolutional Layer）：用于提取局部特征，通过卷积核（滤波器）对输入数据进行扫描，提取边缘、纹理等低级特征，并逐步学习高级特征。**
- **池化层（Pooling Layer）：用于降低特征图的维度，提高计算效率，同时增强模型的平移不变性。常见的池化方法包括最大池化（Max Pooling）和平均池化（Average Pooling）。**



**先进行卷积运算（线性变换），然后通过ReLU进行非线性映射，使得模型能够学习复杂的特征。**

**池化层（Pooling Layer） 只是进行降维操作，没有必要再使用ReLU激活。**



### **降采样（Downsampling） 是指在数据处理中减少数据的数量或分辨率，以降低计算复杂度，同时保留重要信息。**

**在深度学习（特别是卷积神经网络 CNN）中，降采样主要用于降低特征图（Feature Map）的尺寸，同时保留重要特征，提高计算效率，并增强模型的平移不变性。**

------

## **常见的降采样方法**

### **1️⃣ 池化层（Pooling）**

**池化是最常见的降采样方式，主要用于减少特征图尺寸，同时保留最重要的特征信息。**

- **最大池化（Max Pooling）：取池化窗口内的最大值（最常用）。**
- **平均池化（Average Pooling）：取池化窗口内的平均值。**
- **全局平均池化（Global Average Pooling, GAP）：对整个特征图进行平均，生成单一值（常用于替代全连接层）。**



### **2️⃣ 步幅（Stride）**

**在卷积操作时，通过增大步幅（Stride）可以达到降采样的效果。例如：**

- **步幅 1（Stride=1）：滑动窗口每次移动 1 个像素，输出特征图尺寸较大。**
- **步幅 2（Stride=2）：滑动窗口每次移动 2 个像素，输出特征图尺寸减小（降采样）。**

**如果对6×6输入使用3×3卷积核：**

- **步幅 1 → 输出是 4×4**
- **步幅 2 → 输出是 2×2（更小）**





### **🔹 `torch.nn.BatchNorm1d()` 为什么可以缓解过拟合？**

**批归一化（Batch Normalization, BN） 的主要作用是 稳定训练、加速收敛、缓解过拟合。`torch.nn.BatchNorm1d()` 适用于一维输入（如 MLP 的全连接层）

------

### **🔹 `torch.nn.BatchNorm1d()` 的数学原理**

#### **1️⃣ 计算批归一化**

**对一个批次（Batch）中的每个特征维度（channel）进行归一化：**

**$\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i$$\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2$$\hat{x_i} = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$**

**其中：**

- **$x_i$ 是输入数据（每个样本的某个特征）。**
- **$\mu_B$ 和 $\sigma_B^2$ 是该特征在当前 batch 内的均值和方差。**
- **$\epsilon$ 是一个很小的数（如 `1e-5`），防止除零。**

#### **2️⃣ 线性变换**

**为了保证模型仍然具备非线性表达能力，BN 引入了可训练参数 $\gamma$ 和 $\beta$：**

**$y_i = \gamma \hat{x_i} + \beta$**

- **$\gamma$（scale） 控制缩放。**
- **$\beta$（shift） 控制偏移。**
- **这两个参数可以通过反向传播进行学习，使 BN 不会破坏原始特征表示能力。**

------

### **🔹 适用场景**

**✅ MLP（全连接网络）**

```python
nn.Sequential(
    nn.Linear(128, 64),
    nn.BatchNorm1d(64),  # 批归一化
    nn.ReLU(),
    nn.Linear(64, 10)
)
```

**✅ RNN / Transformer（如果每个时间步独立处理）**
 **✅ MoE（Mixture of Experts）（多个专家网络共享特征时）**

------

### **🔹 总结**

**✅ `torch.nn.BatchNorm1d()` 可以缓解过拟合，主要通过：**

1. **引入噪声（batch 统计量变化，类似 Dropout）。**
2. **减少参数敏感性，使网络更稳定。**
3. **防止梯度爆炸或梯度消失，提高训练效率。**

**🚀 在 MLP、CNN、MoE 中都能有效提升模型的泛化能力！**







### **问题分析**

1. **ReLU vs Sigmoid**
   - **ReLU (`max(0, x)`) 避免了梯度消失问题，使深层网络易于训练。**
   - **Sigmoid (`1 / (1 + exp(-x))`) 可能导致梯度消失，收敛速度较慢，通常不推荐用于深度网络的隐藏层。**
2. **ReLU 在输出层是否合适？**
   - **这里的最后一层 `torch.nn.Linear(512, 10)` 之后使用了 ReLU，但理论上输出层一般不需要 ReLU。**
   - **常见改法：去掉 `ReLU()`，或者用 `Softmax()` 直接归一化。**







------

## **1. 熵的起源**

熵最初是热力学中的概念，用来衡量系统的无序程度。后来，信息论（由克劳德·香农 Claude Shannon 提出） 发展了熵的数学定义，用来衡量信息的不确定性。

在信息论中，熵定义为：

**$H(X) = -\sum_{i} P(x_i) \log P(x_i)$**

其中：

- $X$ 是一个随机变量（比如一个分类问题中的类别）。
- $P(x_i)$ 是类别 $x_i$ 的概率。
- **熵 $H(X)$ 衡量的是不确定性，当概率分布越均匀（即不确定性越高），熵就越大。**

------

## **2. 熵在机器学习中的作用**

在机器学习（特别是分类问题）中，熵被用来衡量一个数据集的纯度（purity），即数据中类别的混乱程度。例如：

- **如果一个分类数据集中的所有样本都属于同一个类别（比如全是“猫”），那么数据集的熵为 0（完全确定，没有不确定性）。**
- **如果类别均匀分布（50% 是“猫”，50% 是“狗”），那么熵最大，表示完全不确定。**

这种熵的度量在决策树、随机森林、交叉熵损失等分类算法中被广泛应用。

------

## **4. 熵在交叉熵损失中的应用**

**在分类问题（特别是神经网络中的 Softmax 分类）中，损失函数通常使用交叉熵损失（Cross-Entropy Loss）：**

**$L = -\sum_{i} y_i \log(\hat{y}_i)$**

其中：

- **$y_i$ 是真实类别的独热编码（One-hot encoding）。
- **$\hat{y}_i$ 是模型的预测概率（通常是 Softmax 输出）。
- **交叉熵损失衡量了真实分布 $y$ 与预测分布 $\hat{y}$ 之间的差异，目标是最小化交叉熵，使得模型预测的概率分布更接近真实类别分布。**

**交叉熵损失本质上就是在最小化不确定性，确保模型的预测更加确定。**

------

## **5. 总结**

- 熵的核心概念：衡量不确定性，熵越高，系统越混乱。
- 熵在决策树中的作用：用于选择最佳划分特征，减少数据集的混乱程度（增加纯度）。
- 熵在分类损失函数中的作用：交叉熵用于衡量模型预测与真实分布的差异，优化目标是最小化交叉熵，从而提高分类准确率。

因此，虽然熵最初来自物理学，但它在机器学习中扮演了一个核心角色，帮助我们理解数据的不确定性，并指导模型优化。







## **1. MNIST 数据集的图像信息**

- **大小：28×28 像素**
- **通道数：1（灰度图）**
- **类别数：10（数字 0-9）**

## **3. 各层计算过程**

**让我们一步步分析这个 CNN 结构如何处理 MNIST 28×28 的输入图像：**

1. **第一层卷积（`Conv2d(1, 32, 3, 1, 1)`）**
   - **输入尺寸：(1, 28, 28)**
   - **3×3 卷积，`stride=1`，`padding=1`**
   - **结果尺寸：(32, 28, 28)（保持原尺寸）**
2. **第一层池化（`MaxPool2d(2,2)`）**
   - **2×2 最大池化，步长 2**
   - **结果尺寸：(32, 14, 14)**
3. **第二层卷积（`Conv2d(32, 64, 3, 1, 1)`）**
   - **3×3 卷积，`stride=1`，`padding=1`**
   - **结果尺寸：(64, 14, 14)（保持原尺寸）**
4. **第二层池化（`MaxPool2d(2,2)`）**
   - **2×2 最大池化，步长 2**
   - **结果尺寸：(64, 7, 7)**
5. **展平（Flatten）**
   - **现在的特征图尺寸为 (batch_size, 64, 7, 7)**
   - **需要展平成 (batch_size, 64 × 7 × 7) = (batch_size, 3136)，送入全连接层**
6. **全连接层**
   - **`Linear(3136, 128)`：输入 3136，输出 128**
   - **`Linear(128, 10)`：最终输出 10 维，对应 10 类**





下面是对 `Net` 网络中每一层的名称、含义和作用的详细分析：

### 1. `torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)`

- 名称：卷积层（Convolutional Layer）
- 含义：这是一个 2D 卷积层，它接收 1 个输入通道，并将其映射为 32 个输出通道。
  - `1`：输入通道数。对于 MNIST 数据集，每张图片是灰度图，所以输入通道数为 1。
  - `32`：输出通道数。卷积层会学习 32 个不同的滤波器来提取图像特征。
  - `kernel_size=3`：卷积核的大小是 3x3。
  - `stride=1`：卷积步长为 1，即卷积核每次移动 1 个像素。
  - `padding=1`：为了保持卷积后的输出大小与输入相同，使用了 1 像素的填充（即对输入的每一边加 1 个像素的零填充）。
- 作用：此层负责从输入图像中提取低级特征（如边缘、角点等）。卷积层通过滤波器提取空间信息。

### 2. `torch.nn.ReLU()`

- 名称：ReLU 激活函数（Rectified Linear Unit）
- 含义：ReLU 是一个非线性激活函数，将负值变为零，正值保持不变。对于输入 `x`，ReLU 的输出是 `max(0, x)`。
- 作用：ReLU 激活函数用于增加网络的非线性能力，从而使得网络可以学习复杂的特征和模式。它有助于解决梯度消失问题并加速网络训练。

### 3. `torch.nn.MaxPool2d(kernel_size=2, stride=2)`

- 名称：最大池化层（Max Pooling Layer）
- 含义：池化层用于下采样操作，减少特征图的尺寸，保留最显著的信息。这个池化层使用 2x2 的窗口，步长为 2。
  - `kernel_size=2`：池化窗口的大小是 2x2。
  - `stride=2`：池化窗口的步长是 2，即窗口每次移动 2 个像素。
- 作用：池化层的作用是降维，减小特征图的大小，同时保留关键特征。通过池化，可以降低计算量并防止过拟合。

### 4. `torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)`

- 名称：卷积层（Convolutional Layer）
- 含义：这是第二个卷积层，接收 32 个输入通道，并将其映射为 64 个输出通道。
  - `32`：输入通道数，即上一层的输出特征图的深度。
  - `64`：输出通道数。卷积层将学习 64 个滤波器来提取更高级的特征。
  - `kernel_size=3`：卷积核的大小是 3x3。
  - `stride=1`：步长为 1，意味着卷积核每次移动一个像素。
  - `padding=1`：为了保持卷积后的输出大小与输入相同，使用了 1 像素的填充。
- 作用：此卷积层的作用是提取更加复杂的特征，逐步捕捉图像中的更高级特征。

### 5. `torch.nn.ReLU()`

- 名称：ReLU 激活函数（Rectified Linear Unit）
- 含义：同上，是一个非线性激活函数，将负值变为零，正值保持不变。
- 作用：ReLU 激活函数用于增加网络的非线性性，使得网络能够学习复杂的模式和关系。

### 6. `torch.nn.MaxPool2d(kernel_size=2, stride=2)`

- 名称：最大池化层（Max Pooling Layer）
- 含义：同上，池化层用于下采样，减少特征图的尺寸。
  - `kernel_size=2`：池化窗口的大小是 2x2。
  - `stride=2`：池化窗口的步长为 2。
- 作用：池化层帮助降低特征图的尺寸，从而减少计算量，保持最重要的特征信息。

### 7. `torch.nn.Linear(64 \* 7 \* 7, 128)`

- 名称：全连接层（Fully Connected Layer）
- 含义：这是一个全连接层，将 64 * 7 * 7 个输入特征映射到 128 个输出特征。
  - `64 * 7 * 7`：上一层的输出是 64 个 7x7 的特征图，因此该层的输入维度是 `64 * 7 * 7 = 3136`。
  - `128`：输出特征的维度。该层将输入的特征映射为 128 个特征。
- 作用：该层将卷积层提取的空间特征映射到一个较小的特征空间中，准备进行最终的分类。

### 8. `torch.nn.ReLU()`

- 名称：ReLU 激活函数（Rectified Linear Unit）
- 含义：同上，应用于全连接层的输出。
- 作用：通过应用 ReLU 激活函数，增加网络的非线性能力，使得模型能够拟合更加复杂的函数。

### 9. `torch.nn.Linear(128, 10)`

- 名称：全连接层（Fully Connected Layer）
- 含义：这是最终的全连接层，它将 128 个输入特征映射到 10 个输出特征。
  - `128`：上一层的输出特征数。
  - `10`：输出特征数。每个输出节点代表一个类别（对于 MNIST 数据集来说，表示数字 0-9）。
- 作用：这是模型的输出层，最终将特征映射到 10 个类别的得分，表示每个数字类别的预测得分。











### **1. `nn.Flatten()`**

**`nn.Flatten()` 是一个 PyTorch 层，它的作用是将输入的多维张量展平成一个 1D 张量。具体来说，它会将除了 batch 维度之外的其他所有维度展平成一个向量。通常在处理图像数据时，输入的图像数据可能是一个 4D 张量（batch_size, channels, height, width），`Flatten()` 会将每张图像展平成一个 1D 向量（`channels * height * width`）。**

**例如，如果输入是形状 `(batch_size, 1, 28, 28)`（代表一批 28x28 的单通道图像），`Flatten()` 会将其转换为 `(batch_size, 784)`，即每张图片展平为一个 784 维的向量。**

```python
nn.Flatten()
```

### **2. `view(-1, 784)`**

**`view()` 是一个 PyTorch 中的张量操作，用来改变张量的形状。`view(-1, 784)` 的作用是将输入的张量展平为形状 `(batch_size, 784)`，其中 `-1` 会根据批次大小自动计算。**

**例如：**

- **假设输入是一个形状为 `(batch_size, 1, 28, 28)` 的张量（每张图像是 28x28 的单通道图像），通过 `view(-1, 784)` 后，会得到形状为 `(batch_size, 784)`，即每张图像都被展平成一个 784 维的向量。**



**关系：**

- **`Flatten()` 是用于展平操作，而 `view(-1, 784)` 是 `Flatten()` 的另一种实现方式（手动调整形状）。**



**医学影像分析、医学图像分割；车载人工智能、无人驾驶；实施目标检测YOLO**